{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, esm, time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()  # esm2_t33_650M_UR50D() - layers:33, esm2_t6_8M_UR50D() - layers:6\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load protein sequence data\n",
    "df = pd.read_csv(\"../data/data-seq_raw-ts.csv\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_aa = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "# Replace invalid residues\n",
    "df['aa_seq'] = df['aa_seq'].str.replace(f\"[^{valid_aa}]\", \"\", regex=True)\n",
    "\n",
    "# # Filter invalid sequences\n",
    "# df = df[df['aa_seq'].apply(lambda seq: set(seq).issubset(set(valid_aa)))]\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate sequences to max length\n",
    "max_len = 1600\n",
    "df['aa_seq'] = df['aa_seq'].str[:max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sequences\n",
    "df['id'] = df['file_id'] + \"-\" + df['locus_tag']\n",
    "data = list(zip(df['id'], df['aa_seq']))\n",
    "\n",
    "# Tokenize sequences\n",
    "*_, batch_tokens = batch_converter(data)  # batch_labels, batch_strs, batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to batch\n",
    "batch_size = 32\n",
    "\n",
    "batch_data = batch_tokens.split(batch_size, dim=0)\n",
    "batch_n = len(batch_data)\n",
    "\n",
    "print(\"Number of samples:\", len(data))\n",
    "print(\"Number of batchs:\", batch_n)\n",
    "print(\"First batch shape:\", batch_data[0].shape)\n",
    "print(\"Last batch shape:\", batch_data[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_seq(batch_data):\n",
    "    # Extract per-residue representations\n",
    "    batch_tokens = batch_data.to(device)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    token_representations = results[\"representations\"][33].cpu()\n",
    "    batch_tokens = batch_data.cpu()\n",
    "    \n",
    "    # Generate per-sequence representations via averaging\n",
    "    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "    embed_mean = []\n",
    "\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        embed_mean.append(token_representations[i, 1:tokens_len - 1].mean(0).cpu().numpy())\n",
    "    \n",
    "    embed_mean = np.stack(embed_mean)\n",
    "    \n",
    "    # display process\n",
    "    global step, time_step\n",
    "    step += 1\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step: {step}/{batch_n} | Processing time: {time.time() - time_step:.1f} sec\")\n",
    "        time_step = time.time()\n",
    "    \n",
    "    return embed_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Embed sequences\n",
    "step = 0\n",
    "time_total = time.time()\n",
    "time_step = time.time()\n",
    "embed_mean = list(map(embed_seq, batch_data))\n",
    "\n",
    "print(f\"Total processing time: {time.time() - time_total:.1f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mean = np.concatenate(embed_mean)\n",
    "\n",
    "print(len(df), emb_mean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CgHvhwIq0ip"
   },
   "source": [
    "#### Concatenate each gene info. & embedded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_str = ['file_id', 'organism', 'locus_tag', 'ess']\n",
    "\n",
    "# Convert the pooled features to dataframe & concatenate the each information\n",
    "emb_mean = pd.concat([df[col_str], pd.DataFrame(emb_mean)], axis=1)\n",
    "\n",
    "display(emb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "emb_mean.to_csv(\"../data/data-emb_gen-esm2-ts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
